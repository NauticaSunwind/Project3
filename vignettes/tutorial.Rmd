---
title: "Project 3: STAT302PACKAGEDH Tutorial"
author: "Dairong Han"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Project 3: STAT302PACKAGEDH Tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


## Information
Thank Professor Bryan D. Martin for his teaching in STAT 302 and kindly providing us with the example we use for this vignette.

## Introduction
This package is the project 3 for STAT 302, containing 4 functions:
<p>
*my_t_test
*my_lm
*my_knn_cv
*my_rf_cv
</p>
and a dataset my_gapminder, a dataset from the famous gapminder dataset.
You can install my package from Github by using the following way(s).
```{r install, eval = FALSE}
devtools::install_github("NauticaSunwind/STAT302PACKAGEDH")
```


To begin, we need to load our sample data as well as the following packages
```{r setup}
library(STAT302PACKAGEDH)
library(stringr)
library(ggplot2)
library(kableExtra)
data("my_gapminder")
```

If you are unfamiliar with my_gapminder, you can view a description of the data using:
```{r help}
?my_gapminder
```
or using:
```{r view}
my_gapminder
```
to directly view the dataset.

## Tutorials
In this tutorial, there are demonstrations of how each of the function works.

### my_t_test
The function my_t_test can be used to perform a one-sampled t test to show whether it is able to reject the null hypothesis.

For demonstration, we use **lifeExp** from my_gapminder.

We are going to test the null hypothesis that mean of lifeExp is 60
$$H_0: \mu = 60$$
with the significant level equals 0.05.
$$\alpha = 0.05$$
***

The First example is a two tailed t test.
$$H_a: \mu \neq 60$$
```{r}
my_t_test(my_gapminder$lifeExp, "two.sided", 60)
```
And we can see the t-value, df, p-value and alternative hypothesis from the output. P-value is greater than 0.05, so we cannot reject the null hypothesis.

***

The second example is a one tailed t test for less.
$$H_a: \mu < 60$$
```{r}
my_t_test(my_gapminder$lifeExp, "less", 60)
```
As we can see from the output, p-value is smaller than 0.05 and we can reject the null hypothesis.

***

The third example is also a one tailed t test, but for greater.
$$H_a: \mu > 60$$
```{r}
my_t_test(my_gapminder$lifeExp, "greater", 60)
```
As we can see from the output, p-value is greater than 0.05 and we cannot reject the null hypothesis.

### my_lm
The function my_lm can be used to perform a linear regression. 

For demonstration, we are using **lifeExp** as response variable and **gdpPercap** and **continent** as explanatory variables.
```{r message = FALSE, warning = FALSE}
my_regression <- my_lm(lifeExp ~ gdpPercap + continent, data = my_gapminder)
my_regression
```
According to the regression, we can see that the coefficient for gdpPercap has positive value 0.00045, which means the lifeExp increases 0.00045 as gdpPercap increases 1.

***
Such brings a hypothesis test about gdpPercap coefficient.
We set $H_0$ and $H_a$ by:
$$H_0: coefficient = 0$$
$$H_a: coefficient \neq 0$$
Then we test it by setting significant level 
$$ \alpha = 0.05$$
From the table above, we can find the p-value. <br>
According to the p-value, since it is much smaller than 0.05, we can reject the null hypothesis.

***
And next, we can plot the Actual vs. Fitted values to find out how well our regression model fits. 
```{r}
object <- lifeExp ~ gdpPercap + continent
model <- model.frame(object, my_gapminder)
# extract the explanatory variable x 
x <- model.matrix(object, my_gapminder)
# extract the response variable y
y <- model.response(model) %>% as.matrix()
```
Visuliaze the actual value and the fitted value. 
```{r fig.align="center", fig.width= 5 , fig.height= 4}
# fitted value
# y_hat = x * Beta + se
my_lifeExp <- x %*% my_regression$Estimate + my_regression$Std.Error
my_df <- data.frame("actual" = my_gapminder$lifeExp, "fitted" = my_lifeExp, "color" = my_gapminder$continent) 
my_df %>%
  ggplot(aes(x = fitted, y = actual, color = color)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0) +
  coord_flip() +    
  labs(title = "Actual vs. Fitted Values", x = "Fitted Values", y = "Actual Values", color = "Continent") +
  theme_classic(base_size = 15) +
  theme(plot.title = element_text(hjust = 0.5),
        panel.background = element_rect(fill = "ghostwhite"),
        legend.title = element_text(hjust = 0.5),
        legend.position = c(.3, 1),
        legend.justification = c("right", "top"),
        legend.box.just = "right",
        legend.margin = margin(5, 5, 5, 5),
        legend.box.background = element_rect(colour = "blue"))
```
<br>
According to the final visualization, we can see that the fitted values, compared to the actual values, have better linear relationships in Europe and Oceania than other continents. Thus in order to provide a better fit, we may need to apply other regression methods.

### my_knn_cv
The function my_knn_cv can be used to perform a prediction using k-nearest neighbor methods, and also train and evaluate the model by cross-validation.
For demonstration, we are predicting output class continent using covariates gdpPercap and lifeExp.
```{r}
train <- my_gapminder %>% select(gdpPercap, lifeExp)
cl <- my_gapminder$continent
result <- matrix(NA, nrow = 10, ncol = 2)
rownames(result) <- c(1:10)
for (i in 1:10) {
  output <- my_knn_cv(train, cl, i, 5)
  # cv misclassfication rate
  result[i, 1] <- output$cv_err
  # training misclassification rate
  result[i, 2] <- output$te
}
result <- data.frame("Number of neighbors" = c(1:10), 
                     "cv misclassification rate" = result[, 1],
                     "training misclassification rate" = result[, 2])
kable_styling(kable(result))
```
Cross validation splits the data into **k** different folds, among which **k-1** folds are used to train the model and the left fold is used to test the model. It is useful because we can use it to find the optimal test error, so that we can use the full set of data to train the final model, and finally generate predictions.
According to the table, we would choose different models basedon different misclassification rates. Based on the training misclassification rates, we choose 1_nn, where k_nn = 1, and choose 10_nn, k_nn = 10 if based on cv misclassification rates. In practice, I would choose 5_nn, k_nn = 5, where neither the training misclassification rate nor the cv misclassification rate is tending to extreme value. 

### my_rf_cv
The function my_rf_cv can be used to perform a prediction using random forest method and also train and evaluate the model by cross validation.
For demonstration, we are making prediction of lifeExp using covariate gdpPercap, iterating through k in c(2, 5, 10) each 30 times.
```{r}
cv_error <- matrix(NA, nrow = 90, ncol = 2)
cv_error[, 1] <- rep(c(2, 5, 10), each = 30)
row <- 1
for(k in c(2, 5, 10)) {
  for(i in 1:30) {
    cv_error[row, 2] <- my_rf_cv(k)
    row <- row + 1
  }
}
```
```{r fig.align="center", fig.height= 10, fig.width= 10}
my_df <- data.frame("k" = cv_error[, 1], "mse" = cv_error[, 2])
my_df %>% 
  ggplot(aes(x = factor(k), y = mse, fill = factor(k))) +
  geom_boxplot() +
  labs(title = "MSE of K folds", x = "Number of Folds", y = "MSE", 
       fill = "Number of Folds") +
  theme_classic(base_size = 15) +
  theme(plot.title = element_text(hjust = 0.5),
        panel.background = element_rect(fill = "ghostwhite"),
        legend.title = element_text(hjust = 0.5, size = 10),
        legend.margin = margin(5, 5, 5, 5))
```
```{r}
mse_sum <- my_df %>% 
  group_by(k) %>%
  summarise(mean = mean(mse), sd = sd(mse))
kable_styling(kable(mse_sum))
```
According to the boxplot and the table, as k increases, we can see that the range of mse and the standard deviation are tending to decrease, while the median and mean are tending to increase.Because the more folds exist, the more we can evaluate the data, and our prediction would be more accurate as the MSE and standard deviation decrease due to the decrease of variance.
